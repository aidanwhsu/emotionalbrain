{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "Yo2LzgHU6Vd_"
      },
      "id": "Yo2LzgHU6Vd_"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()\n",
        "from tensorflow.keras.optimizers.legacy import Adam"
      ],
      "metadata": {
        "id": "izCnkFCu5Tfy"
      },
      "id": "izCnkFCu5Tfy",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "tw2hA_X85IXz"
      },
      "id": "tw2hA_X85IXz"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('content')\n",
        "import os\n",
        "print('reached here')\n",
        "print(os.listdir('./content/MyDrive/Me/Images'))\n",
        "os.chdir('./content/MyDrive/Me/Images')\n",
        "print(os.listdir('.'))\n",
        "#!cd './drive/Me/Images'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyCFuk4gJAZT",
        "outputId": "9505dd4c-26e3-4b6c-dd17-6ddf329a9e42"
      },
      "id": "WyCFuk4gJAZT",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at content\n",
            "reached here\n",
            "['ds003548']\n",
            "['ds003548']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e2893f39",
      "metadata": {
        "id": "e2893f39"
      },
      "outputs": [],
      "source": [
        "fmri_data = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b394bc61",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b394bc61",
        "outputId": "50d6b5f7-bc2e-4f98-f14e-2f46c481ca9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading person 1\n",
            "loading person 2\n",
            "loading person 3\n",
            "loading person 4\n",
            "loading person 5\n",
            "loading person 6\n",
            "loading person 7\n",
            "loading person 8\n",
            "loading person 9\n",
            "loading person 10\n",
            "loading person 11\n",
            "loading person 12\n",
            "loading person 13\n",
            "loading person 14\n",
            "loading person 15\n",
            "loading person 16\n"
          ]
        }
      ],
      "source": [
        "for i in range(1,17):\n",
        "    print('loading person', i)\n",
        "    padi = str(i).rjust(2,'0')\n",
        "    fmri_data['sub_'+str(i)] = {}\n",
        "    for run in range(1,6):\n",
        "        img = nib.load(f'./ds003548/sub-{padi}/func/sub-{padi}_task-emotionalfaces_run-{run}_bold.nii.gz')\n",
        "        img_arr = np.array(img.dataobj)\n",
        "        fmri_data['sub_'+str(i)][str(run)] = img_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1fc520e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fc520e9",
        "outputId": "bb0a0ff4-34ba-4542-9cb6-9e7e17e9cde8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 35, 185)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Shape of data is x,y,z,t\n",
        "fmri_data['sub_1']['5'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fac35293",
      "metadata": {
        "id": "fac35293"
      },
      "outputs": [],
      "source": [
        "inputs = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6770c78d",
      "metadata": {
        "id": "6770c78d",
        "outputId": "9e4a648b-b3bb-4f59-b137-1f51a751309a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading run 1\n",
            "loading run 2\n",
            "loading run 3\n",
            "loading run 4\n",
            "loading run 5\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "for i in range(1,6):\n",
        "    print('loading run', i)\n",
        "    with open(f\"./ds003548/task-emotionalfaces_run-{i}_events.tsv\") as file:\n",
        "        tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
        "        inputs['run_'+str(i)] = [x for x in tsv_file]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "21f8d609",
      "metadata": {
        "id": "21f8d609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bda9ac5-7d5d-4daf-e168-e19c24a1f8f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['onset', 'duration', 'trial_type'],\n",
              " ['0', '30', 'sad'],\n",
              " ['30', '30', 'neutral'],\n",
              " ['60', '30', 'blank'],\n",
              " ['90', '30', 'angry'],\n",
              " ['120', '30', 'scrambled'],\n",
              " ['150', '30', 'happy'],\n",
              " ['180', '30', 'sad'],\n",
              " ['210', '30', 'neutral'],\n",
              " ['240', '30', 'blank'],\n",
              " ['270', '30', 'angry'],\n",
              " ['300', '30', 'scrambled'],\n",
              " ['330', '30', 'happy'],\n",
              " ['360', '10', 'end'],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "inputs['run_2']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\"After their presentation, participants had to wait for 10 seconds before concluding the sequence, in order to capture the hemodynamic response (HR) elicited by the last stimuli.\"\n",
        "Turn end into previous emotion?"
      ],
      "metadata": {
        "id": "0quXVlFBzJgC"
      },
      "id": "0quXVlFBzJgC"
    },
    {
      "cell_type": "code",
      "source": [
        "#####   CHANGE END TO MOST RECENT EMOTION\n",
        "print(\"Last trial type:\",inputs['run_2'][-2][-1])\n",
        "print(\"2nd last trial type:\", inputs['run_2'][-3][-1])\n",
        "\n",
        "for runs in inputs:  #run_1, run_2, run_3, run_4, run_5\n",
        "  inputs[runs][-2][-1] = inputs[runs][-3][-1]\n",
        "\n",
        "#check\n",
        "for runs in inputs:\n",
        "  print(inputs[runs][-2][-1])\n"
      ],
      "metadata": {
        "id": "69NH8K_hzJLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f80bf46-26a0-466f-a758-9258f46f05ba"
      },
      "id": "69NH8K_hzJLq",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last trial type: end\n",
            "2nd last trial type: happy\n",
            "blank\n",
            "happy\n",
            "sad\n",
            "scrambled\n",
            "blank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "97c5032b",
      "metadata": {
        "id": "97c5032b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629ac61c-7672-4555-c608-cbd09878ec1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['trial_type', 'trial_type', 'trial_type', 'trial_type',\n",
              "       'trial_type', 'trial_type', 'trial_type', 'trial_type',\n",
              "       'trial_type', 'trial_type', 'trial_type', 'trial_type', 'blank',\n",
              "       'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank',\n",
              "       'blank', 'blank', 'blank', 'blank', 'scrambled', 'scrambled',\n",
              "       'scrambled', 'scrambled', 'scrambled', 'scrambled', 'scrambled',\n",
              "       'scrambled', 'scrambled', 'scrambled', 'scrambled', 'scrambled',\n",
              "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
              "       'happy', 'happy', 'happy', 'happy', 'happy', 'sad', 'sad', 'sad',\n",
              "       'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad',\n",
              "       'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry',\n",
              "       'angry', 'angry', 'angry', 'angry', 'angry', 'neutral', 'neutral',\n",
              "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
              "       'neutral', 'neutral', 'neutral', 'neutral', 'happy', 'happy',\n",
              "       'happy', 'happy', 'happy', 'happy', 'happy', 'happy', 'happy',\n",
              "       'happy', 'happy', 'happy', 'sad', 'sad', 'sad', 'sad', 'sad',\n",
              "       'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'sad', 'angry', 'angry',\n",
              "       'angry', 'angry', 'angry', 'angry', 'angry', 'angry', 'angry',\n",
              "       'angry', 'angry', 'angry', 'neutral', 'neutral', 'neutral',\n",
              "       'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral',\n",
              "       'neutral', 'neutral', 'neutral', 'scrambled', 'scrambled',\n",
              "       'scrambled', 'scrambled', 'scrambled', 'scrambled', 'scrambled',\n",
              "       'scrambled', 'scrambled', 'scrambled', 'scrambled', 'scrambled',\n",
              "       'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank',\n",
              "       'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank',\n",
              "       'blank', 'blank', 'blank', 'blank', 'blank', 'blank', 'blank',\n",
              "       'blank', 'blank', 'blank'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "np.repeat([x[2] for x in inputs['run_1'][:-1]],12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "69a61296",
      "metadata": {
        "id": "69a61296"
      },
      "outputs": [],
      "source": [
        "#[3dim, label]. have t briefly to match with label, or just have x and y be sorted\n",
        "#shape=(185*n, *3dim)\n",
        "#list(data.values())\n",
        "#something = [list(x.values()) for x in list(fmri_data.values())]\n",
        "#len(something[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fmri_data['sub_1']['1'].shape)\n",
        "print(np.transpose(fmri_data['sub_1']['1']).shape)"
      ],
      "metadata": {
        "id": "lK_ZUm91TppQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb3ca31-9076-4785-eeea-c7c5a0d14d16"
      },
      "id": "lK_ZUm91TppQ",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 64, 35, 185)\n",
            "(185, 35, 64, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "KIzY0RC08ZfP"
      },
      "id": "KIzY0RC08ZfP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FULL DATA "
      ],
      "metadata": {
        "id": "EE-mcV158ctk"
      },
      "id": "EE-mcV158ctk"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.zeros(shape=(64,64,35,185*4)) #X_train takes first 4 runs from all\n",
        "for i in range(1,17):\n",
        "  for j in range(1,5):\n",
        "    X_train[:,:,:,185*(j-1):185*(j)] = fmri_data['sub_'+str(i)][str(j)]\n",
        "    \n",
        "X_train = np.transpose(X_train)\n",
        "\n",
        "y_train = []\n",
        "for j in range(1,5):\n",
        "  data = np.repeat([x[2] for x in inputs['run_'+str(j)][1:-1]], 15)[:185]\n",
        "  for item in data:\n",
        "    y_train.append(item)\n",
        "\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_test = np.transpose(fmri_data['sub_1']['5'])\n",
        "y_test = np.repeat([x[2] for x in inputs['run_5'][1:-1]], 15)[:185]\n",
        "\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "sIGVnhUaltDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e0105c-0b65-45f9-e45c-88e451f0f1a3"
      },
      "id": "sIGVnhUaltDJ",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(740,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CHECK SHAPES\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j-Vac5JJbc1",
        "outputId": "2131ab33-d0a7-4152-b2d0-6ad68df09800"
      },
      "id": "1j-Vac5JJbc1",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(740, 35, 64, 64)\n",
            "(185, 35, 64, 64)\n",
            "(740,)\n",
            "(185,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing"
      ],
      "metadata": {
        "id": "JqDpmTPy9fwZ"
      },
      "id": "JqDpmTPy9fwZ"
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn emotions into specific numbers\n",
        "#indexing for y. \n",
        "emotion = ['blank', 'scrambled','happy','sad','angry','neutral']\n",
        "y_train_numbered = y_train\n",
        "y_test_numbered = y_test\n",
        "for i in range(len(y_train)):\n",
        "  y_train_numbered[i] = emotion.index(y_train[i])\n",
        "for i in range(len(y_test)):\n",
        "  y_test_numbered[i] = emotion.index(y_test[i])\n",
        "\n",
        "print(y_train_numbered)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBqqeLKzFTf2",
        "outputId": "d867f92c-98be-4103-bfb8-4535e49d8af0"
      },
      "id": "zBqqeLKzFTf2",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '1'\n",
            " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '2' '2' '2' '2' '2' '2'\n",
            " '2' '2' '2' '2' '2' '2' '2' '2' '2' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
            " '3' '3' '3' '3' '3' '3' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4'\n",
            " '4' '4' '4' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5'\n",
            " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '3' '3' '3'\n",
            " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '4' '4' '4' '4' '4' '4'\n",
            " '4' '4' '4' '4' '4' '4' '4' '4' '4' '5' '5' '5' '5' '5' '5' '5' '5' '5'\n",
            " '5' '5' '5' '5' '5' '5' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
            " '1' '1' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
            " '0' '0' '0' '0' '0' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
            " '3' '3' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '0'\n",
            " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '4' '4' '4' '4'\n",
            " '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '1' '1' '1' '1' '1' '1' '1'\n",
            " '1' '1' '1' '1' '1' '1' '1' '1' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
            " '2' '2' '2' '2' '2' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
            " '3' '3' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '0'\n",
            " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '4' '4' '4' '4'\n",
            " '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '1' '1' '1' '1' '1' '1' '1'\n",
            " '1' '1' '1' '1' '1' '1' '1' '1' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2'\n",
            " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '5' '5' '5' '5' '5' '5' '5' '5'\n",
            " '5' '5' '5' '5' '5' '5' '5' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
            " '0' '0' '0' '0' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4'\n",
            " '4' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '2' '2'\n",
            " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '3' '3' '3' '3' '3'\n",
            " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '5' '5' '5' '5' '5' '5' '5' '5'\n",
            " '5' '5' '5' '5' '5' '5' '5' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
            " '0' '0' '0' '0' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4' '4'\n",
            " '4' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '2' '2'\n",
            " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '3' '3' '3' '3' '3'\n",
            " '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '2' '2' '2'\n",
            " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '4' '4' '4' '4' '4'\n",
            " '4' '4' '4' '4' '4' '4' '4' '4' '4' '5' '5' '5' '5' '5' '5' '5' '5' '5'\n",
            " '5' '5' '5' '5' '5' '5' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
            " '0' '0' '0' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
            " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '2' '2' '2'\n",
            " '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '4' '4' '4' '4' '4' '4'\n",
            " '4' '4' '4' '4' '4' '4' '4' '4' '4' '5' '5' '5' '5' '5' '5' '5' '5' '5'\n",
            " '5' '5' '5' '5' '5' '5' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
            " '0' '0' '0' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3' '3'\n",
            " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
            " '1' '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Some visualization. of fMRI volumes\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# X_train.shape\n",
        "# t = 37\n",
        "\n",
        "# f, axarr = plt.subplots(1,5, figsize=(11, 11)) \n",
        "# axarr[0].imshow(X_train[t,:,:,7])\n",
        "# axarr[1].imshow(X_train[t,:,:,14])\n",
        "# axarr[2].imshow(X_train[t,:,:,21])\n",
        "# axarr[3].imshow(X_train[t,:,:,28])\n",
        "# axarr[4].imshow(X_train[t,:,:,34])\n",
        "\n",
        "# print('emotion: ',emotion[int(y_train[t])])\n",
        "# print('t: ',t)"
      ],
      "metadata": {
        "id": "wS580yHIn4hT"
      },
      "id": "wS580yHIn4hT",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Idea of our attempt at data augmentation. \n",
        "\n",
        "# from torchvision import transforms\n",
        "\n",
        "# # Define data augmentation transforms\n",
        "# data_transforms = transforms.Compose([\n",
        "#     transforms.RandomRotation(10),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "\n",
        "# # Apply data augmentation during dataset creation\n",
        "# train_dataset = YourDataset(train_data, transform=data_transforms)\n",
        "\n",
        "# # Use separate transforms for validation and testing\n",
        "# val_transforms = transforms.ToTensor()\n",
        "# test_transforms = transforms.ToTensor()\n",
        "# val_dataset = YourDataset(val_data, transform=val_transforms)\n",
        "# test_dataset = YourDataset(test_data, transform=test_transforms)"
      ],
      "metadata": {
        "id": "jVRnTcIQncGv"
      },
      "id": "jVRnTcIQncGv",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "# PyTorch model"
      ],
      "metadata": {
        "id": "zLILIIV5nnnk"
      },
      "id": "zLILIIV5nnnk"
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "lr = 1e-4\n",
        "dropout_rate = 0.5"
      ],
      "metadata": {
        "id": "XzSa0iFr_ydB"
      },
      "id": "XzSa0iFr_ydB",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#z-score test\n",
        "x_mean = np.mean(X_train)\n",
        "x_std = np.std(X_train)"
      ],
      "metadata": {
        "id": "zTuNSUctCme4"
      },
      "id": "zTuNSUctCme4",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr_centered = (X_train - x_mean)/x_std\n",
        "X_ts_centered = (X_test - x_mean)/x_std"
      ],
      "metadata": {
        "id": "0cnzerRLCo3D"
      },
      "id": "0cnzerRLCo3D",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_5d = X_train.reshape((X_train.shape[0],1, X_train.shape[1],X_train.shape[2],X_train.shape[3]))\n",
        "X_test_5d = X_test.reshape((X_test.shape[0],1, X_test.shape[1],X_test.shape[2],X_test.shape[3]))\n",
        "X_train_5d = torch.from_numpy(X_train_5d).type(torch.float)\n",
        "X_test_5d = torch.from_numpy(X_test_5d).type(torch.float)\n",
        "y_train_torch = torch.from_numpy(y_train.astype(int))\n",
        "y_test_torch = torch.from_numpy(y_test.astype(int))"
      ],
      "metadata": {
        "id": "C5dfBbvithy9"
      },
      "id": "C5dfBbvithy9",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN MODEL\n",
        "class Conv3DNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Conv3DNet, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1, 8, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv3d(8, 16, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        #self.fc1 = nn.Linear(32 * 6 * 6 * 6, 512)\n",
        "        self.fc1 = nn.Linear(8192, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "        #x = x.view(-1, 32 * 6 * 6 * 6)\n",
        "        x = x.view(-1, 8192)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "27L0ggentiOK"
      },
      "id": "27L0ggentiOK",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TESTING MORE NEURONS & ONE EXTRA LAYER. NO DIFFERENCE IN ACCURACY\n",
        "\n",
        "# class Conv3DNet(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Conv3DNet, self).__init__()\n",
        "#         self.conv1 = nn.Conv3d(1, 8, kernel_size=3, padding=2)\n",
        "#         self.bn1 = nn.BatchNorm3d(8)\n",
        "#         self.conv2 = nn.Conv3d(8, 16, kernel_size=3, padding=2)\n",
        "#         self.bn2 = nn.BatchNorm3d(16)\n",
        "#         self.conv3 = nn.Conv3d(16, 32, kernel_size=3, padding=2)\n",
        "#         self.bn3 = nn.BatchNorm3d(32)\n",
        "#         self.conv4 = nn.Conv3d(32, 128, kernel_size=3, padding=2)\n",
        "#         self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "#         #self.fc1 = nn.Linear(32 * 6 * 6 * 6, 512)\n",
        "#         self.fc1 = nn.Linear(12800, 512)\n",
        "#         self.fc2 = nn.Linear(512, 10)\n",
        "#         self.sig = nn.Sigmoid()\n",
        "#     def forward(self, x):\n",
        "#         x = self.pool(torch.sigmoid(self.conv1(x)))\n",
        "#         x = self.pool(torch.sigmoid(self.conv2(x)))\n",
        "#         x = self.pool(torch.sigmoid(self.conv3(x)))\n",
        "#         x = self.pool(torch.sigmoid(self.conv4(x)))\n",
        "#         #x = x.view(-1, 32 * 6 * 6 * 6)\n",
        "#         x = x.view(-1, 12800)\n",
        "#         x = self.sig(self.fc1(x))\n",
        "#         x = self.fc2(x)\n",
        "#         return x"
      ],
      "metadata": {
        "id": "nNlP4KsQI87_"
      },
      "id": "nNlP4KsQI87_",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model, optimizer, and loss function\n",
        "model = Conv3DNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model for num_epoch epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(zip(X_train_5d, y_train_torch)):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.unsqueeze(0))\n",
        "        loss = criterion(outputs, labels.unsqueeze(0).long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    print('Epoch [%d], loss: %.4f' % (epoch+1, running_loss / len(X_train_5d)))\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "# model.eval()\n",
        "# correct = 0\n",
        "# total = 0\n",
        "# with torch.no_grad():\n",
        "#     for i, (inputs, labels) in enumerate(zip(X_test_5d, y_test_torch)):\n",
        "#         outputs = model(inputs.unsqueeze(0))\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += 1\n",
        "#         correct += (predicted == labels.unsqueeze(0)).sum().item()\n",
        "# print('Accuracy of the network on the %d validation images: %d %%' % (len(X_test_5d), 100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9rKHWuYtUdV",
        "outputId": "9ba342d9-5ac8-4457-f452-52ba7a3049a4"
      },
      "id": "j9rKHWuYtUdV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], loss: 42.8486\n",
            "Epoch [2], loss: 1.8355\n",
            "Epoch [3], loss: 2.1686\n",
            "Epoch [4], loss: 1.8284\n",
            "Epoch [5], loss: 1.8212\n",
            "Epoch [6], loss: 1.8189\n",
            "Epoch [7], loss: 1.8169\n",
            "Epoch [8], loss: 1.8144\n",
            "Epoch [9], loss: 1.8127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy computations\n",
        "def compute_accuracy(x,y):\n",
        "  correct = 0\n",
        "\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for i, (inputs, labels) in enumerate(zip(x, y)):\n",
        "          outputs = model(inputs.unsqueeze(0))\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += 1\n",
        "          correct += (predicted == labels.unsqueeze(0)).sum().item()\n",
        "  print('Accuracy on %d images: %d %%' % (len(x), 100 * correct / total))\n",
        "\n",
        "print(\"train acc: \")\n",
        "compute_accuracy(X_train_5d, y_train_torch)\n",
        "print(\"test acc: \")\n",
        "compute_accuracy(X_test_5d, y_test_torch)"
      ],
      "metadata": {
        "id": "JA1nM1NSi96H"
      },
      "id": "JA1nM1NSi96H",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}